{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"/fs/archive/share/mm_datasets/mmE5/mmE5-synthetic/\"\n",
    "subsets = [\"Classification\", \"Retrieval\", \"VQA\"]\n",
    "mme5_dataset =  {}\n",
    "for subset in subsets:\n",
    "    subset_data = load_dataset(\n",
    "                        dataset_path,\n",
    "                        subset,\n",
    "                        split=\"train\",\n",
    "                    )\n",
    "    mme5_dataset[subset] = subset_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Find a Wikipedia image that answers this question: The Shard London Bridge is taller than nearby buildings?\"\n",
    "for subset_name, subset_data in mme5_dataset.items():\n",
    "    for data in subset_data:\n",
    "        if query_text in data[\"qry\"]:\n",
    "            print(f\"Found in subset: {subset_name}\")\n",
    "            print(data)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in mme5_dataset[\"Retrieval\"]:\n",
    "    if data[\"modality\"] in [\"T2I\", \"T2IT\"] and data[\"qry\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of retrieval samples with T2I or T2IT modality and <|image_1|> in qry: {count}\")\n",
    "\n",
    "count = 0\n",
    "for data in mme5_dataset[\"Classification\"]:\n",
    "    if data[\"modality\"] in [\"T2I\", \"T2IT\"] and data[\"qry\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of classification samples with T2I or T2IT modality and <|image_1|> in qry: {count}\")\n",
    "\n",
    "count = 0\n",
    "for data in mme5_dataset[\"VQA\"]:\n",
    "    if data[\"modality\"] in [\"T2I\", \"T2IT\"] and data[\"qry\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of VQA samples with T2I or T2IT modality and <|image_1|> in qry: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in mme5_dataset[\"Retrieval\"]:\n",
    "    if data[\"modality\"] in [\"I2T\", \"IT2T\"] and data[\"pos_text\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of retrieval samples with I2T or IT2T modality and <|image_1|> in pos_text: {count}\")\n",
    "count = 0\n",
    "for data in mme5_dataset[\"Classification\"]:\n",
    "    if data[\"modality\"] in [\"I2T\", \"IT2T\"] and data[\"pos_text\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of classification samples with I2T or IT2T modality and <|image_1|> in pos_text: {count}\")\n",
    "count = 0\n",
    "for data in mme5_dataset[\"VQA\"]:\n",
    "    if data[\"modality\"] in [\"I2T\", \"IT2T\"] and data[\"pos_text\"].count(\"<|image_1|>\"):\n",
    "        count += 1\n",
    "print(f\"Number of VQA samples with I2T or IT2T modality and <|image_1|> in pos_text: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in mme5_dataset[\"Retrieval\"]:\n",
    "    if data[\"modality\"] in [\"I2T\", \"IT2T\"]:\n",
    "        neg_texts = eval(data[\"neg_text\"])\n",
    "        for neg_text in neg_texts:\n",
    "            if neg_text.count(\"<|image_1|>\"):\n",
    "                count += 1\n",
    "                break\n",
    "print(f\"Number of retrieval samples with I2T or IT2T modality and <|image_1|> in neg_text: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/fs/archive/share/mm_datasets/mmE5/mmE5-MMEB-hardneg/\"\n",
    "\n",
    "subsets = ['TAT-DQA', 'ArxivQA', 'InfoSeek_it2t', 'InfoSeek_it2it', 'ImageNet_1K', 'N24News', 'HatefulMemes', 'SUN397', 'VOC2007', 'InfographicsVQA', 'ChartQA', 'A-OKVQA', 'DocVQA', 'OK-VQA', 'Visual7W', 'VisDial', 'CIRR', 'NIGHTS', 'WebQA', 'VisualNews_i2t', 'VisualNews_t2i', 'MSCOCO_i2t', 'MSCOCO_t2i', 'MSCOCO']\n",
    "mmeb_hardneg_dataset = {}\n",
    "for subset in subsets:\n",
    "    subset_data = load_dataset(\n",
    "                        dataset_path,\n",
    "                        subset,\n",
    "                        split=\"train\",\n",
    "                    )\n",
    "    mmeb_hardneg_dataset[subset] = subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset_name, subset_data in mmeb_hardneg_dataset.items():\n",
    "    for data in subset_data:\n",
    "        if query_text in data[\"qry\"]:\n",
    "            print(f\"Found in MMEB hardneg subset: {subset_name}\")\n",
    "            print(data)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset_name, subset_data in mmeb_hardneg_dataset.items():\n",
    "    count = 0\n",
    "    for data in subset_data:\n",
    "        if \"<|image_1|>\" in data[\"qry\"] and data[\"qry_image_path\"] == \"\":\n",
    "            count += 1\n",
    "    print(f\"Number of samples in {subset_name} with <|image_1|> in qry and empty qry_image_path: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
